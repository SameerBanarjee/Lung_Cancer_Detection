{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCQWCKcp4SMF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv(\"Lung Cancer Data.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop('GENDER', axis=1)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "EodjZi484mhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "fDd-Vatu4xIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.astype('float')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "te-ygubw5DSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['LUNG_CANCER'] = data['LUNG_CANCER'].astype('int')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "D2FBX0UL5IA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('LUNG_CANCER', axis=1)\n",
        "X = np.asarray(X)\n",
        "X[:5]"
      ],
      "metadata": {
        "id": "eO815oTE5MLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = data['LUNG_CANCER']\n",
        "Y = np.asarray(Y)\n",
        "Y[:5]"
      ],
      "metadata": {
        "id": "6e9Hdemn5RKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
        "X[0:5]"
      ],
      "metadata": {
        "id": "Ny3Qa4sl5XxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "data.hist(bins=50, figsize=(20,15))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "z56Hzb115fhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.2, random_state=42)\n",
        "print(f\"Rows in Training Set: {len(X_train)}\")\n",
        "print(f\"Rows in Test Set: {len(X_test)}\")"
      ],
      "metadata": {
        "id": "7bnYwDx35n0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(X, Y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "print(f\"Rows in Training Set: {len(X_train)}\")\n",
        "print(f\"Rows in Test Set: {len(X_test)}\")"
      ],
      "metadata": {
        "id": "P76HWOAR55-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "model = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,Y_train)\n",
        "# model = KNeighborsClassifier(n_neighbors = 4).fit(X_train, Y_train)\n",
        "# model = svm.SVC(kernel='rbf')\n",
        "# model.fit(X_train, Y_train)\n",
        "model"
      ],
      "metadata": {
        "id": "iXblNZ_k6A6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_hat = model.predict(X_test)\n",
        "Y_hat"
      ],
      "metadata": {
        "id": "BUoMkOCK6EmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "def Model_Report(Y_test, Y_hat):\n",
        "    precision = precision_score(Y_test, Y_hat)\n",
        "    print(f'Precision: {precision}')\n",
        "    recall = recall_score(Y_test, Y_hat)\n",
        "    print(f'Recall Score: {recall}')\n",
        "    conf_matrix = confusion_matrix(Y_test, Y_hat)\n",
        "    print(f'Confusion Matrix: {conf_matrix}')\n",
        "    logloss = log_loss(Y_test, Y_hat)\n",
        "    print(f'Log Loss: {logloss}')"
      ],
      "metadata": {
        "id": "bsfMMkCq6KnI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model_Report(Y_test, Y_hat)"
      ],
      "metadata": {
        "id": "69_98JBH6QxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\n",
        "dump(model, 'CancerDetection.joblib')"
      ],
      "metadata": {
        "id": "kmAEb_dl6V40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from joblib import load\n",
        "from sklearn import preprocessing\n"
      ],
      "metadata": {
        "id": "n2-3_yef6ae-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model from the joblib file\n",
        "model = load('CancerDetection.joblib')\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "_ujMoJqN9TNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from joblib import load\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = load('CancerDetection.joblib')\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Create new diverse test cases\n",
        "new_data = pd.DataFrame({\n",
        "    'Age': [25, 35, 45, 60, 70, 50],  # Various ages\n",
        "    'Smoking': [0, 0, 1, 0, 1, 1],  # Smoking status (0 = No, 1 = Yes)\n",
        "    'PollutionExposure': [1, 1, 2, 0, 3, 1],  # Levels of pollution exposure\n",
        "    'LungCapacity': [90, 85, 70, 95, 60, 80],  # Lung capacity percentages\n",
        "    'GeneticRisk': [0, 1, 2, 0, 3, 2],  # Genetic risk levels\n",
        "    'ChestPain': [0, 0, 1, 0, 1, 1],  # Chest pain presence (0 = No, 1 = Yes)\n",
        "    'PEER_PRESSURE':[0,0,1,0,0,1],\n",
        "    'FATIGUE':[0,0,1,0,1,1],\n",
        "    'ALLERGY':[0,0,1,0,1,1],\n",
        "    'WHEEZING':[0,0,1,0,0,1],\n",
        "    'ALCOHOL CONSUMING':[1,0,0,1,0,1],\n",
        "    'COUGHING':[0,0,1,0,1,1],\n",
        "    'SHORTNESS OF BREATH':[0,0,1,0,1,1],\n",
        "    'SWALLOWING DIFFICULTY':[0,0,1,0,1,1]\n",
        "})\n",
        "print(\"New Data for Testing:\")\n",
        "print(new_data)\n",
        "\n",
        "# Apply StandardScaler to match training preprocessing\n",
        "scaler = preprocessing.StandardScaler().fit(new_data)\n",
        "X_new = scaler.transform(new_data)\n",
        "\n",
        "# Predict outcomes\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "# Interpret predictions\n",
        "outcome = [\"Cancer Detected\" if pred == 1 else \"No Cancer Detected\" for pred in predictions]\n",
        "\n",
        "# Combine new data with predictions\n",
        "new_data['Prediction'] = outcome\n",
        "print(\"Predictions for New Data:\")\n",
        "print(new_data)\n"
      ],
      "metadata": {
        "id": "JdydiK03_oqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate\n"
      ],
      "metadata": {
        "id": "BGr1DOG4jbje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Convert DataFrame to table\n",
        "table = tabulate(new_data, headers='keys', tablefmt='pretty')\n",
        "print(table)\n"
      ],
      "metadata": {
        "id": "mV7YI78RjlEU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}